{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b50a97b-66b9-4121-8452-44bfb236c8ea",
   "metadata": {},
   "source": [
    "Current local llm doesn't have a well-trained version yet, so just a simple version shows that the code is capable of load local llm and lora weight."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf9e03b-a513-4b81-a75e-243f38a3c84a",
   "metadata": {},
   "source": [
    "## 初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3851d799-7162-4e73-acab-3c13cb1e43bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c1ede08-857f-4592-9093-d7e5a37ce245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/mnt/workspace/code/ModelScopeGPT/agent/demo', '/opt/conda/lib/python38.zip', '/opt/conda/lib/python3.8', '/opt/conda/lib/python3.8/lib-dynload', '', '/opt/conda/lib/python3.8/site-packages', '/opt/conda/lib/python3.8/site-packages/tinycudann-1.6-py3.8-linux-x86_64.egg', '../', '../../']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../../')\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad42f062-5664-44f8-82b7-6995a4f512a0",
   "metadata": {},
   "source": [
    "## Load cfg and initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84f06ad1-34c5-4032-9254-aab88d7fe19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 13:41:49,991 - modelscope - INFO - PyTorch version 1.12.1+cu113 Found.\n",
      "2023-08-07 13:41:49,995 - modelscope - INFO - Loading ast index from /mnt/workspace/.cache/modelscope/ast_indexer\n",
      "2023-08-07 13:41:50,073 - modelscope - INFO - Loading done! Current index file version is 1.8.1, with md5 190567084f4c777b03348021255ae8f9 and a total number of 893 components indexed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../config/cfg_tool.json\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('../config/.env', override=True)\n",
    "\n",
    "import os\n",
    "from modelscope.utils.config import Config\n",
    "\n",
    "# model_cfg_file = os.getenv('LOCAL_LLM_CONFIG_FILE')\n",
    "tool_cfg_file = os.getenv('TOOL_CONFIG_FILE') \n",
    "\n",
    "# print(model_cfg_file)\n",
    "print(tool_cfg_file)\n",
    "\n",
    "# model_cfg = Config.from_file(model_cfg_file)\n",
    "tool_cfg = Config.from_file(tool_cfg_file)\n",
    "\n",
    "\n",
    "model_name = 'qwen-7b'\n",
    "model_cfg = {\n",
    "    'qwen-7b':{\n",
    "        'model_id': 'qwen/Qwen-7B-Chat',\n",
    "        'model_revision': 'v1.0.1',\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbbee3d8-067b-405d-b630-2a74d4e78b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-07 13:42:33,115] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 13:42:37,717 - modelscope - INFO - Use user-specified model revision: v1.0.1\n",
      "The model is automatically converting to bf16 for faster inference. If you want to disable the automatic precision, please manually add bf16/fp16/fp32=True to \"AutoModelForCausalLM.from_pretrained\".\n",
      "Try importing flash-attention for faster inference...\n",
      "Warning: import flash_attn rotary fail, please install FlashAttention rotary to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/rotary\n",
      "Warning: import flash_attn rms_norm fail, please install FlashAttention layer_norm to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/layer_norm\n",
      "Warning: import flash_attn fail, please install FlashAttention to get higher efficiency https://github.com/Dao-AILab/flash-attention\n",
      "2023-08-07 13:43:26,528 - modelscope - INFO - Use user-specified model revision: v1.0.1\n"
     ]
    }
   ],
   "source": [
    "from modelscope_agent.agent import AgentExecutor\n",
    "from modelscope_agent.llm import QWen\n",
    "from modelscope_agent.prompt import QWenPromptGenerator\n",
    "from modelscope_agent.output_parser import QwenOutputParser\n",
    "\n",
    "llm = QWen(model_cfg)\n",
    "\n",
    "output_parser = QwenOutputParser()\n",
    "prompt_generator = QWenPromptGenerator()\n",
    "\n",
    "agent = AgentExecutor(llm, tool_cfg, prompt_generator=prompt_generator, output_parser=output_parser)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522adcf0-b200-44d1-b0fb-891fbd7951d9",
   "metadata": {},
   "source": [
    "## 音频生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0033690b-67dd-49d8-8ce2-5ed5f0a00584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|prompt1: Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "1. {\"name\": \"modelscope_speech-generation\", \"description\": \"文本转语音服务，将文字转换为自然而逼真的语音，可配置男声/女声\", \"parameters\": [{\"name\": \"input\", \"description\": \"要转成语音的文本\", \"required\": true}, {\"name\": \"gender\", \"description\": \"用户身份\", \"required\": true}]}\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [{tool_names}]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can be repeated zero or more times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin!\n",
      "\n",
      "\n",
      "\n",
      "Question: 写一个 2023上海世界人工智能大会 20 字以内的口号，并念出来\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "**************************************************round 1**************************************************"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Thought: 我应该使用文本转语音服务来生成口号并进行朗读。\n",
       "Action: modelscope_speech-generation\n",
       "Action Input: {\"input\": \"2023上海世界人工智能大会\", \"gender\": \"male\"}\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: 我应该使用文本转语音服务来生成口号并进行朗读。\n",
      "Action: modelscope_speech-generation\n",
      "Action Input: {\"input\": \"2023上海世界人工智能大会\", \"gender\": \"male\"}\n",
      "\n",
      "modelscope_speech-generation {'input': '2023上海世界人工智能大会', 'gender': 'male'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 13:43:43,629 - modelscope - INFO - Model revision not specified, use the latest revision: v1.0.2\n",
      "2023-08-07 13:43:44,721 - modelscope - INFO - initiate model from /mnt/workspace/.cache/modelscope/damo/speech_sambert-hifigan_tts_zh-cn_16k\n",
      "2023-08-07 13:43:44,721 - modelscope - INFO - initiate model from location /mnt/workspace/.cache/modelscope/damo/speech_sambert-hifigan_tts_zh-cn_16k.\n",
      "2023-08-07 13:43:44,725 - modelscope - INFO - initialize model from /mnt/workspace/.cache/modelscope/damo/speech_sambert-hifigan_tts_zh-cn_16k\n",
      "2023-08-07 13:43:44,733 - modelscope - INFO - am_config=/mnt/workspace/.cache/modelscope/damo/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhitian_emo/am/config.yaml voc_config=/mnt/workspace/.cache/modelscope/damo/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhitian_emo/voc/config.yaml\n",
      "2023-08-07 13:43:44,733 - modelscope - INFO - audio_config=/mnt/workspace/.cache/modelscope/damo/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhitian_emo/audio_config.yaml\n",
      "2023-08-07 13:43:44,733 - modelscope - INFO - am_ckpts=OrderedDict([(0, '/mnt/workspace/.cache/modelscope/damo/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhitian_emo/am/ckpt/checkpoint_0.pth')])\n",
      "2023-08-07 13:43:44,734 - modelscope - INFO - voc_ckpts=OrderedDict([(0, '/mnt/workspace/.cache/modelscope/damo/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhitian_emo/voc/ckpt/checkpoint_0.pth'), (1, '/mnt/workspace/.cache/modelscope/damo/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhitian_emo/voc/ckpt/checkpoint_1.pth')])\n",
      "2023-08-07 13:43:44,734 - modelscope - INFO - se_path=/mnt/workspace/.cache/modelscope/damo/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhitian_emo/am/se.npy se_model_path=/mnt/workspace/.cache/modelscope/damo/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhitian_emo/se/ckpt/se.onnx\n",
      "2023-08-07 13:43:44,734 - modelscope - INFO - mvn_path=/mnt/workspace/.cache/modelscope/damo/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhitian_emo/am/mvn.npy\n",
      "2023-08-07 13:43:44,760 - modelscope - INFO - am_config=/mnt/workspace/.cache/modelscope/damo/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhibei_emo/am/config.yaml voc_config=/mnt/workspace/.cache/modelscope/damo/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhibei_emo/voc/config.yaml\n",
      "2023-08-07 13:43:44,761 - modelscope - INFO - audio_config=/mnt/workspace/.cache/modelscope/damo/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhibei_emo/audio_config.yaml\n",
      "2023-08-07 13:43:44,761 - modelscope - INFO - am_ckpts=OrderedDict([(0, '/mnt/workspace/.cache/modelscope/damo/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhibei_emo/am/ckpt/checkpoint_0.pth')])\n",
      "2023-08-07 13:43:44,761 - modelscope - INFO - voc_ckpts=OrderedDict([(0, '/mnt/workspace/.cache/modelscope/damo/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhibei_emo/voc/ckpt/checkpoint_0.pth'), (1, '/mnt/workspace/.cache/modelscope/damo/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhibei_emo/voc/ckpt/checkpoint_1.pth')])\n",
      "2023-08-07 13:43:44,761 - modelscope - INFO - se_path=/mnt/workspace/.cache/modelscope/damo/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhibei_emo/am/se.npy se_model_path=/mnt/workspace/.cache/modelscope/damo/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhibei_emo/se/ckpt/se.onnx\n",
      "2023-08-07 13:43:44,762 - modelscope - INFO - mvn_path=/mnt/workspace/.cache/modelscope/damo/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhibei_emo/am/mvn.npy\n",
      "2023-08-07 13:43:44,788 - modelscope - INFO - am_config=/mnt/workspace/.cache/modelscope/damo/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhizhe_emo/am/config.yaml voc_config=/mnt/workspace/.cache/modelscope/damo/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhizhe_emo/voc/config.yaml\n",
      "2023-08-07 13:43:44,789 - modelscope - INFO - audio_config=/mnt/workspace/.cache/modelscope/damo/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhizhe_emo/audio_config.yaml\n",
      "2023-08-07 13:43:44,789 - modelscope - INFO - am_ckpts=OrderedDict([(0, '/mnt/workspace/.cache/modelscope/damo/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhizhe_emo/am/ckpt/checkpoint_0.pth')])\n",
      "2023-08-07 13:43:44,790 - modelscope - INFO - voc_ckpts=OrderedDict([(0, '/mnt/workspace/.cache/modelscope/damo/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhizhe_emo/voc/ckpt/checkpoint_0.pth'), (1, '/mnt/workspace/.cache/modelscope/damo/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhizhe_emo/voc/ckpt/checkpoint_1.pth')])\n",
      "2023-08-07 13:43:44,790 - modelscope - INFO - se_path=/mnt/workspace/.cache/modelscope/damo/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhizhe_emo/am/se.npy se_model_path=/mnt/workspace/.cache/modelscope/damo/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhizhe_emo/se/ckpt/se.onnx\n",
      "2023-08-07 13:43:44,790 - modelscope - INFO - mvn_path=/mnt/workspace/.cache/modelscope/damo/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhizhe_emo/am/mvn.npy\n",
      "2023-08-07 13:43:44,816 - modelscope - INFO - am_config=/mnt/workspace/.cache/modelscope/damo/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhiyan_emo/am/config.yaml voc_config=/mnt/workspace/.cache/modelscope/damo/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhiyan_emo/voc/config.yaml\n",
      "2023-08-07 13:43:44,816 - modelscope - INFO - audio_config=/mnt/workspace/.cache/modelscope/damo/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhiyan_emo/audio_config.yaml\n",
      "2023-08-07 13:43:44,817 - modelscope - INFO - am_ckpts=OrderedDict([(0, '/mnt/workspace/.cache/modelscope/damo/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhiyan_emo/am/ckpt/checkpoint_0.pth')])\n",
      "2023-08-07 13:43:44,817 - modelscope - INFO - voc_ckpts=OrderedDict([(0, '/mnt/workspace/.cache/modelscope/damo/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhiyan_emo/voc/ckpt/checkpoint_0.pth'), (1, '/mnt/workspace/.cache/modelscope/damo/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhiyan_emo/voc/ckpt/checkpoint_1.pth')])\n",
      "2023-08-07 13:43:44,817 - modelscope - INFO - se_path=/mnt/workspace/.cache/modelscope/damo/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhiyan_emo/am/se.npy se_model_path=/mnt/workspace/.cache/modelscope/damo/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhiyan_emo/se/ckpt/se.onnx\n",
      "2023-08-07 13:43:44,817 - modelscope - INFO - mvn_path=/mnt/workspace/.cache/modelscope/damo/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhiyan_emo/am/mvn.npy\n",
      "2023-08-07 13:43:52,771 - modelscope - WARNING - No preprocessor field found in cfg.\n",
      "2023-08-07 13:43:52,772 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
      "2023-08-07 13:43:52,772 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': '/mnt/workspace/.cache/modelscope/damo/speech_sambert-hifigan_tts_zh-cn_16k'}. trying to build by task and model information.\n",
      "2023-08-07 13:43:52,773 - modelscope - WARNING - No preprocessor key ('sambert-hifigan', 'text-to-speech') found in PREPROCESSOR_MAP, skip building preprocessor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pinyin_en_mix_dict failed\n",
      "Load pinyin_en_mix_dict failed\n",
      "Load pinyin_en_mix_dict failed\n",
      "Load pinyin_en_mix_dict failed\n",
      "Load pinyin_en_mix_dict failed\n",
      "Load pinyin_en_mix_dict failed\n",
      "Load pinyin_en_mix_dict failed\n",
      "Load pinyin_en_mix_dict failed\n",
      "Load pinyin_en_mix_dict failed\n",
      "Load pinyin_en_mix_dict failed\n",
      "Load pinyin_en_mix_dict failed\n",
      "Load pinyin_en_mix_dict failed\n",
      "Load pinyin_en_mix_dict failed\n",
      "Load pinyin_en_mix_dict failed\n",
      "Load pinyin_en_mix_dict failed\n",
      "Load pinyin_en_mix_dict failed\n",
      "text.cc: festival_Text_init\n",
      "Removing weight norm...\n",
      "|prompt2: Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "1. {\"name\": \"modelscope_speech-generation\", \"description\": \"文本转语音服务，将文字转换为自然而逼真的语音，可配置男声/女声\", \"parameters\": [{\"name\": \"input\", \"description\": \"要转成语音的文本\", \"required\": true}, {\"name\": \"gender\", \"description\": \"用户身份\", \"required\": true}]}\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [{tool_names}]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can be repeated zero or more times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin!\n",
      "\n",
      "\n",
      "\n",
      "Question: 写一个 2023上海世界人工智能大会 20 字以内的口号，并念出来\n",
      "Thought: 我应该使用文本转语音服务来生成口号并进行朗读。\n",
      "Action: modelscope_speech-generation\n",
      "Action Input: {\"input\": \"2023上海世界人工智能大会\", \"gender\": \"male\"}\n",
      "\n",
      "Observation: {'result': <audio id=audio controls= preload=none> <source id=wav src=./tmp/tmpbu2f5bn1/ef41fa24-a831-420d-824d-e3654d63b4c0.wav> </audio>}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "**************************************************round 2**************************************************"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Thought: I now know the final answer.\n",
       "Final Answer: 2023上海世界人工智能大会：智能引领未来。"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'result': <audio id=audio controls= preload=none> <source id=wav src=./tmp/tmpbu2f5bn1/ef41fa24-a831-420d-824d-e3654d63b4c0.wav> </audio>}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "available_tool_list = [\n",
    "    # 'modelscope_text-translation-zh2en',\n",
    "    # 'modelscope_video-generation',\n",
    "    # 'modelscope_image-chat',\n",
    "    'modelscope_speech-generation',\n",
    "]\n",
    "agent.set_available_tools(available_tool_list)\n",
    "agent.reset()\n",
    "agent.run(\"写一个 2023上海世界人工智能大会 20 字以内的口号，并念出来\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a76e6a6-3334-4078-b87f-60ee9eec3bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|prompt1: Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "1. {\"name\": \"modelscope_image-generation\", \"description\": \"图像生成服务，针对文本输入，生成对应的图片\", \"parameters\": [{\"name\": \"text\", \"description\": \"用户输入的文本信息\", \"required\": true}]}\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [{tool_names}]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can be repeated zero or more times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin!\n",
      "\n",
      "Question: 写一个 2023上海世界人工智能大会 20 字以内的口号，并念出来Thought: 我应该使用文本转语音服务来生成口号并进行朗读。\n",
      "Action: modelscope_speech-generation\n",
      "Action Input: {\"input\": \"2023上海世界人工智能大会\", \"gender\": \"male\"}\n",
      "\n",
      "Observation: {'result': <audio id=audio controls= preload=none> <source id=wav src=./tmp/tmpbu2f5bn1/ef41fa24-a831-420d-824d-e3654d63b4c0.wav> </audio>}\n",
      "Thought: I now know the final answer.\n",
      "Final Answer: 2023上海世界人工智能大会：智能引领未来。\n",
      "\n",
      "Question: 生成一张有花有酒的图片\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "**************************************************round 1**************************************************"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Thought: 我应该使用图像生成服务来生成一张有花有酒的图片。\n",
       "Action: modelscope_image-generation\n",
       "Action Input: {\"text\": \"a picture of flowers and wine\"}\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: 我应该使用图像生成服务来生成一张有花有酒的图片。\n",
      "Action: modelscope_image-generation\n",
      "Action Input: {\"text\": \"a picture of flowers and wine\"}\n",
      "\n",
      "modelscope_image-generation {'text': 'a picture of flowers and wine'}\n",
      "|prompt2: Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "1. {\"name\": \"modelscope_image-generation\", \"description\": \"图像生成服务，针对文本输入，生成对应的图片\", \"parameters\": [{\"name\": \"text\", \"description\": \"用户输入的文本信息\", \"required\": true}]}\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [{tool_names}]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can be repeated zero or more times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin!\n",
      "\n",
      "Question: 写一个 2023上海世界人工智能大会 20 字以内的口号，并念出来Thought: 我应该使用文本转语音服务来生成口号并进行朗读。\n",
      "Action: modelscope_speech-generation\n",
      "Action Input: {\"input\": \"2023上海世界人工智能大会\", \"gender\": \"male\"}\n",
      "\n",
      "Observation: {'result': <audio id=audio controls= preload=none> <source id=wav src=./tmp/tmpbu2f5bn1/ef41fa24-a831-420d-824d-e3654d63b4c0.wav> </audio>}\n",
      "Thought: I now know the final answer.\n",
      "Final Answer: 2023上海世界人工智能大会：智能引领未来。\n",
      "\n",
      "Question: 生成一张有花有酒的图片\n",
      "Thought: 我应该使用图像生成服务来生成一张有花有酒的图片。\n",
      "Action: modelscope_image-generation\n",
      "Action Input: {\"text\": \"a picture of flowers and wine\"}\n",
      "\n",
      "Observation: {'result': ![IMAGEGEN](https://dashscope-result-sh.oss-cn-shanghai.aliyuncs.com/1e5e2015/20230807/1344/d2466788-22a3-4b80-961d-82f8351dff08-1.png?Expires=1691473456&OSSAccessKeyId=LTAI5tQZd8AEcZX6KZV4G8qL&Signature=%2Fm6IStOcJhjLuUKkUbWRUoQ41fc%3D)}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "**************************************************round 2**************************************************"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Thought: I now know the final answer.\n",
       "Final Answer: 成功生成了一张图片！图片位于<https://dashscope-result-sh.oss-cn-shanghai.aliyuncs.com/1e5e2015/20230807/1344/d2466788-22a3-4b80-961d-82f8351dff08-1.png>，您可以下载或者直接使用该图片。"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'result': ![IMAGEGEN](https://dashscope-result-sh.oss-cn-shanghai.aliyuncs.com/1e5e2015/20230807/1344/d2466788-22a3-4b80-961d-82f8351dff08-1.png?Expires=1691473456&OSSAccessKeyId=LTAI5tQZd8AEcZX6KZV4G8qL&Signature=%2Fm6IStOcJhjLuUKkUbWRUoQ41fc%3D)}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "available_tool_list = [\n",
    "    'modelscope_image-generation',\n",
    "]\n",
    "agent.set_available_tools(available_tool_list)\n",
    "\n",
    "agent.run(\"生成一张有花有酒的图片\", remote=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4893759c-21cf-4fb7-9a2e-1e31186d5aec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
