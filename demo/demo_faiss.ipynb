{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdf9e03b-a513-4b81-a75e-243f38a3c84a",
   "metadata": {},
   "source": [
    "## 初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3851d799-7162-4e73-acab-3c13cb1e43bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c1ede08-857f-4592-9093-d7e5a37ce245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/mnt/workspace/code/ModelScopeGPT/agent/demo', '/opt/conda/lib/python38.zip', '/opt/conda/lib/python3.8', '/opt/conda/lib/python3.8/lib-dynload', '', '/opt/conda/lib/python3.8/site-packages', '/opt/conda/lib/python3.8/site-packages/tinycudann-1.6-py3.8-linux-x86_64.egg', '../']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad42f062-5664-44f8-82b7-6995a4f512a0",
   "metadata": {},
   "source": [
    "## Load cfg and initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84f06ad1-34c5-4032-9254-aab88d7fe19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-03 14:38:23,599 - modelscope - INFO - PyTorch version 1.12.1+cu113 Found.\n",
      "2023-08-03 14:38:23,604 - modelscope - INFO - Loading ast index from /mnt/workspace/.cache/modelscope/ast_indexer\n",
      "2023-08-03 14:38:23,634 - modelscope - INFO - Loading done! Current index file version is 1.7.0, with md5 bbb5a1af05c4dbbcda7f138f8a12f0bf and a total number of 861 components indexed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../config/cfg_model.json\n",
      "../config/cfg_tool.json\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('../config/.env', override=True)\n",
    "\n",
    "import os\n",
    "from modelscope.utils.config import Config\n",
    "\n",
    "model_cfg_file = os.getenv('LLM_CONFIG_FILE')\n",
    "tool_cfg_file = os.getenv('TOOL_CONFIG_FILE') \n",
    "\n",
    "print(model_cfg_file)\n",
    "print(tool_cfg_file)\n",
    "\n",
    "model_cfg = Config.from_file(model_cfg_file)\n",
    "tool_cfg = Config.from_file(tool_cfg_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbbee3d8-067b-405d-b630-2a74d4e78b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelscope_agent.agent import AgentExecutor\n",
    "from modelscope_agent.llm.ms_gpt import ModelScopeGPT\n",
    "\n",
    "llm = ModelScopeGPT(model_cfg)\n",
    "agent = AgentExecutor(llm, tool_cfg)\n",
    "agent.set_available_tools(['modelscope_image-generation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2c55c7-8b24-4d48-ade6-8e1e80760172",
   "metadata": {},
   "source": [
    "## 向量库配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9cada29c-1892-4ec9-901f-615a3c5da0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import ModelScopeEmbeddings, DashScopeEmbeddings\n",
    "\n",
    "from langchain.vectorstores import FAISS\n",
    "import faiss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a76e6a6-3334-4078-b87f-60ee9eec3bac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">6</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3 # embedding_device = 'cpu'</span>                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4 # model_id = 'damo/nlp_corom_sentence-embedding_chinese-base'</span>                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5 # embeddings = ModelScopeEmbeddings(model_id=model_id)</span>                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>6 embeddings = DashScopeEmbeddings(model=<span style=\"color: #808000; text-decoration-color: #808000\">\"text-embedding-v1\"</span>)                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">7 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">pydantic.main.BaseModel.__init__</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">341</span>                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ValidationError: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> validation error for DashScopeEmbeddings\n",
       "__root__\n",
       "  Did not find dashscope_api_key, please add an environment variable `DASHSCOPE_API_KEY` which contains it, or pass\n",
       "`dashscope_api_key` as a named parameter. <span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #800080; text-decoration-color: #800080\">value_error</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m6\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3 \u001b[0m\u001b[2m# embedding_device = 'cpu'\u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m4 \u001b[0m\u001b[2m# model_id = 'damo/nlp_corom_sentence-embedding_chinese-base'\u001b[0m                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m5 \u001b[0m\u001b[2m# embeddings = ModelScopeEmbeddings(model_id=model_id)\u001b[0m                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m6 embeddings = DashScopeEmbeddings(model=\u001b[33m\"\u001b[0m\u001b[33mtext-embedding-v1\u001b[0m\u001b[33m\"\u001b[0m)                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m7 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92mpydantic.main.BaseModel.__init__\u001b[0m:\u001b[94m341\u001b[0m                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mValidationError: \u001b[0m\u001b[1;36m1\u001b[0m validation error for DashScopeEmbeddings\n",
       "__root__\n",
       "  Did not find dashscope_api_key, please add an environment variable `DASHSCOPE_API_KEY` which contains it, or pass\n",
       "`dashscope_api_key` as a named parameter. \u001b[1m(\u001b[0m\u001b[33mtype\u001b[0m=\u001b[35mvalue_error\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# embedding\n",
    "# embedding_name = 'GanymedeNil/text2vec-large-chinese'\n",
    "# embedding_device = 'cpu'\n",
    "# model_id = 'damo/nlp_corom_sentence-embedding_chinese-base'\n",
    "# embeddings = ModelScopeEmbeddings(model_id=model_id)\n",
    "embeddings = DashScopeEmbeddings(model=\"text-embedding-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8607a8f-bc06-469d-9008-a357d4920dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "import re\n",
    "from typing import List\n",
    "from modelscope.pipelines import pipeline\n",
    "\n",
    "\n",
    "# ref: https://github.com/chatchat-space/langchain-ChatGLM/blob/master/textsplitter/ali_text_splitter.py\n",
    "class AliTextSplitter(CharacterTextSplitter):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def split_text(self, text: str) -> List[str]:\n",
    "\n",
    "        p = pipeline(\n",
    "            task=\"document-segmentation\",\n",
    "            model='damo/nlp_bert_document-segmentation_chinese-base',\n",
    "            device=\"cpu\")\n",
    "        result = p(documents=text)\n",
    "        sent_list = [i for i in result[\"text\"].split(\"\\n\\t\") if i]\n",
    "        return sent_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6c66f65-eda0-4b2e-9e2a-9d5ec80a74d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-03 14:40:08,538 - modelscope - INFO - Model revision not specified, use the latest revision: v1.0.1\n",
      "2023-08-03 14:40:08,713 - modelscope - INFO - initiate model from /mnt/workspace/.cache/modelscope/damo/nlp_bert_document-segmentation_chinese-base\n",
      "2023-08-03 14:40:08,713 - modelscope - INFO - initiate model from location /mnt/workspace/.cache/modelscope/damo/nlp_bert_document-segmentation_chinese-base.\n",
      "2023-08-03 14:40:08,716 - modelscope - INFO - initialize model from /mnt/workspace/.cache/modelscope/damo/nlp_bert_document-segmentation_chinese-base\n",
      "2023-08-03 14:40:10,480 - modelscope - WARNING - No preprocessor field found in cfg.\n",
      "2023-08-03 14:40:10,481 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
      "2023-08-03 14:40:10,482 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': '/mnt/workspace/.cache/modelscope/damo/nlp_bert_document-segmentation_chinese-base'}. trying to build by task and model information.\n",
      "2023-08-03 14:40:10,482 - modelscope - WARNING - No preprocessor key ('bert-for-document-segmentation', 'document-segmentation') found in PREPROCESSOR_MAP, skip building preprocessor.\n",
      "2023-08-03 14:40:12,140 - modelscope - INFO - Model revision not specified, use the latest revision: v1.0.1\n",
      "2023-08-03 14:40:12,308 - modelscope - INFO - initiate model from /mnt/workspace/.cache/modelscope/damo/nlp_bert_document-segmentation_chinese-base\n",
      "2023-08-03 14:40:12,309 - modelscope - INFO - initiate model from location /mnt/workspace/.cache/modelscope/damo/nlp_bert_document-segmentation_chinese-base.\n",
      "2023-08-03 14:40:12,312 - modelscope - INFO - initialize model from /mnt/workspace/.cache/modelscope/damo/nlp_bert_document-segmentation_chinese-base\n",
      "2023-08-03 14:40:14,178 - modelscope - WARNING - No preprocessor field found in cfg.\n",
      "2023-08-03 14:40:14,179 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
      "2023-08-03 14:40:14,179 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': '/mnt/workspace/.cache/modelscope/damo/nlp_bert_document-segmentation_chinese-base'}. trying to build by task and model information.\n",
      "2023-08-03 14:40:14,180 - modelscope - WARNING - No preprocessor key ('bert-for-document-segmentation', 'document-segmentation') found in PREPROCESSOR_MAP, skip building preprocessor.\n",
      "2023-08-03 14:40:23,340 - modelscope - INFO - Model revision not specified, use the latest revision: v1.0.1\n",
      "2023-08-03 14:40:23,516 - modelscope - INFO - initiate model from /mnt/workspace/.cache/modelscope/damo/nlp_bert_document-segmentation_chinese-base\n",
      "2023-08-03 14:40:23,517 - modelscope - INFO - initiate model from location /mnt/workspace/.cache/modelscope/damo/nlp_bert_document-segmentation_chinese-base.\n",
      "2023-08-03 14:40:23,520 - modelscope - INFO - initialize model from /mnt/workspace/.cache/modelscope/damo/nlp_bert_document-segmentation_chinese-base\n",
      "2023-08-03 14:40:25,178 - modelscope - WARNING - No preprocessor field found in cfg.\n",
      "2023-08-03 14:40:25,179 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
      "2023-08-03 14:40:25,180 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': '/mnt/workspace/.cache/modelscope/damo/nlp_bert_document-segmentation_chinese-base'}. trying to build by task and model information.\n",
      "2023-08-03 14:40:25,180 - modelscope - WARNING - No preprocessor key ('bert-for-document-segmentation', 'document-segmentation') found in PREPROCESSOR_MAP, skip building preprocessor.\n"
     ]
    }
   ],
   "source": [
    "# 导入文件\n",
    "filepaths = ['tmp/ms.txt', 'tmp/china.txt', 'tmp/xiyouji.txt']\n",
    "\n",
    "def load_file(filepaths, sentence_size=100):\n",
    "    textsplitter = AliTextSplitter()\n",
    "    docs = []\n",
    "    for filepath in filepaths:\n",
    "        if not filepath.lower().endswith(\".txt\"):\n",
    "            continue\n",
    "        loader = TextLoader(filepath, autodetect_encoding=True)\n",
    "        docs+=(loader.load_and_split(textsplitter))\n",
    "    \n",
    "    return docs\n",
    "docs = load_file(filepaths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04441b3b-d16c-4cd1-8934-bbf69bdf0ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 建立索引\n",
    "vector_store = FAISS.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d765417-135f-44c7-b696-706c575256e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 3\n",
    "def search_query_wrapper(query):\n",
    "    \n",
    "    search_docs = vector_store.similarity_search(query, k=top_k)\n",
    "    \n",
    "    search_res = '\\n'.join([f'[{idx+1}] {s.page_content}' for idx, s in enumerate(search_docs)])\n",
    "    \n",
    "    final_query = f'<|startofsearch|>\\nsearch results: \\n{search_res.strip()}\\n<|endofsearch|>\\n{query}'\n",
    "\n",
    "    return final_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6590e60b-f483-43c9-94c1-7f55a9b81d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|startofsearch|>\n",
      "search results: \n",
      "[1] 7版本及以上。我们推荐您使用Anaconda进行安装。\n",
      "[2] 安装深度学习框架。\n",
      "[3] 安装ModelScope Library。我们提供两种安装方式，您可选择适合的方式进行安装。\n",
      "<|endofsearch|>\n",
      "魔搭安装\n"
     ]
    }
   ],
   "source": [
    "query_without_search = '魔搭安装'\n",
    "# query = '生成一个xxx的图片，用最强大的基模型'\n",
    "\n",
    "query_with_search = search_query_wrapper(query_without_search)\n",
    "\n",
    "print(query_with_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ffd7e437-1017-4e00-ace9-4780e3d90ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|prompt1: <|system|>:你是达摩院的ModelScopeGPT（魔搭助手），你是个大语言模型， 是2023年达摩院的工程师训练得到的。你有多种能力，可以通过插件集成魔搭社区的模型api来回复用户的问题，还能解答用户使用模型遇到的问题和模型知识相关问答。\n",
      " 当前对话可以使用的插件信息如下，请自行判断是否需要调用插件来解决当前用户问题。若需要调用插件，则需要将插件调用请求按照json格式给出，必须包含api_name、parameters字段，并在其前后使用<|startofthink|>和<|endofthink|>作为标志。然后你需要根据插件API调用结果生成合理的答复； 若无需调用插件，则直接给出对应回复即可。\n",
      "\n",
      "1. {\"name\": \"modelscope_image-generation\", \"description\": \"图像生成服务，针对文本输入，生成对应的图片\", \"parameters\": [{\"name\": \"text\", \"description\": \"用户输入的文本信息\", \"required\": true}]}\n",
      "\n",
      "\n",
      "\n",
      "<|user|>:魔搭安装\n",
      "\n",
      "<|assistant|>:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "**************************************************round 1**************************************************"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "<!DOCTYPE html>\n",
       "<html>\n",
       "  <head>\n",
       "    <meta charset=\"utf-8\" />\n",
       "    <meta\n",
       "      name=\"viewport\"\n",
       "      content=\"width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no\"\n",
       "    />\n",
       "    <meta property=\"og:title\" content=\"ModelScope 魔搭社区\" />\n",
       "    <meta property=\"og:url\" content=\"//modelscope.cn/\" />\n",
       "    <meta property=\"og:image\" content=\"//img.alicdn.com/imgextra/i4/O1CN01fvt4it25rEZU4Gjso_!!6000000007579-2-tps-128-128.png\" />\n",
       "    <meta property=\"og:description\" content=\"ModelScope——汇聚各领域先进的机器学习模型，提供模型探索体验、推理、训练、部署和应用的一站式服务。在这里，共建模型开源社区，发现、学习、定制和分享心仪的模型。\" />\n",
       "\n",
       "     <link rel=\"icon\" type=\"image/x-icon\" href=\"//g.alicdn.com/sail-web/maas/0.10.33/favicon/128.ico\">\n",
       "    <link\n",
       "      rel=\"stylesheet\"\n",
       "      href=\"//g.alicdn.com/sail-web/maas/0.10.33/umi.css\"\n",
       "    />\n",
       "    <script>\n",
       "      window.routerBase = \"/\";\n",
       "      window.publicPath = \"//g.alicdn.com\\/sail-web\\/maas\\/0.10.33/\";\n",
       "      window.__detail_data__ =  null ;\n",
       "      window.MODELSCOPE_SITE_MODE = \"COMMON\";\n",
       "      window.MODELSCOPE_DEMO_SCHEMA_VERSION = '0.0.1'\n",
       "    </script>\n",
       "    <script>\n",
       "      \n",
       "    </script>\n",
       "    <script\n",
       "      src=\"//g.alicdn.com/alilog/mlog/aplus_v2.js\"\n",
       "      id=\"beacon-aplus\"\n",
       "    ></script>\n",
       "<script src=\"//g.alicdn.com/vip/havana-login/0.3.2/js/mini-login-embedder-min.js\" crossorigin=\"anonymous\"></script>\n",
       "  </head>\n",
       "  <body>\n",
       "    <div id=\"root\"></div>\n",
       "    <script src=\"//g.alicdn.com/sail-web/maas/0.10.33/umi.js\" crossorigin=\"anonymous\"></script>\n",
       "  </body>\n",
       "</html>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.reset()\n",
    "agent.run(query_without_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f26e11ac-469b-44a9-9dc3-043dcf50a331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|prompt1: <|system|>:你是达摩院的ModelScopeGPT（魔搭助手），你是个大语言模型， 是2023年达摩院的工程师训练得到的。你有多种能力，可以通过插件集成魔搭社区的模型api来回复用户的问题，还能解答用户使用模型遇到的问题和模型知识相关问答。\n",
      " 当前对话可以使用的插件信息如下，请自行判断是否需要调用插件来解决当前用户问题。若需要调用插件，则需要将插件调用请求按照json格式给出，必须包含api_name、parameters字段，并在其前后使用<|startofthink|>和<|endofthink|>作为标志。然后你需要根据插件API调用结果生成合理的答复； 若无需调用插件，则直接给出对应回复即可。\n",
      "\n",
      "1. {\"name\": \"modelscope_image-generation\", \"description\": \"图像生成服务，针对文本输入，生成对应的图片\", \"parameters\": [{\"name\": \"text\", \"description\": \"用户输入的文本信息\", \"required\": true}]}\n",
      "\n",
      "\n",
      "\n",
      "<|user|>:\n",
      "search results: \n",
      "[1] 7版本及以上。我们推荐您使用Anaconda进行安装。\n",
      "[2] 安装深度学习框架。\n",
      "[3] 安装ModelScope Library。我们提供两种安装方式，您可选择适合的方式进行安装。\n",
      "\n",
      "\n",
      "魔搭安装\n",
      "\n",
      "<|assistant|>:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "**************************************************round 1**************************************************"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "根据搜索结果，我们建议您使用Anaconda进行安装深度学习框架，然后再安装ModelScope Library。您可以选择魔搭社区提供的两种安装方式之一进行安装。如果您想了解更多关于安装的细节，请参考搜索结果中的第一个链接。"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.reset()\n",
    "agent.run(query_with_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c3f4e45-2f97-4a29-b253-599a3c979b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|startofsearch|>\n",
      "search results: \n",
      "[1] 猪八戒，法号猪悟能。他原为天界率领八万兵马的天蓬元帅，后来因酒醉后调戏嫦娥而被贬入凡间，转世成了猪脸人身的怪物，名为猪刚鬛。唐三藏与孙悟空来到高老庄，高老庄长老告诉他们，三年前招的女婿是妖怪，求唐僧孙悟空解救，于是孙悟空便变化成高翠兰，打倒猪刚鬛。当猪刚鬛得知孙悟空是唐三藏的弟子后，便主动投入三藏门下，并告知三藏自己也被观音菩萨告知必须以协助三藏取经来赎罪。猪八戒懂得三十六般变化，手持九齿钉耙作为武器。在旅途中，他好色、懒惰、窝囊的种种表现不时拖累师徒，更屡屡陷唐三藏于生死关头，但他偶尔也有优异的表现。在取得佛经后，猪八戒被封净坛使者菩萨，负责代替十方诸佛下凡享用香火供品。\n",
      "[2] \t孙悟空孕育自一颗位于东胜神州花果山上的灵石，该石吸纳日月精华，内育仙胞，一日迸裂，产一石卵，见风化为石猴。它率领众猴在花果山称王，被敬拜为“美猴王”。它因见到其它猴子老死而兴起求得长生不死之法的念头，便前往斜月三星洞拜菩提祖师为师。菩提祖师赐它“孙悟空”之名，授他七十二般变化之法和斤斗云。\n",
      "[3] 沙悟净如同猪八戒一样，沙悟净原本也是天界的一名将军。他本是卷帘大将，但因为不小心打破玻璃盏而让他受到玉皇大帝的惩罚，被贬入凡间后、他成了吃人妖怪。他住在流沙河中，袭击渡河船只。沙悟净的武器是降妖宝杖，他在吃人之后会将他们的头骨收集起来，无聊的时候把玩它们。后来观音菩萨告诉他、将会有位从东土而来的唐僧路经此地，观音要他拜唐僧为师。当唐僧和他的弟子来到流沙河时，沙悟净和孙悟空、猪八戒大打出手，当他得知他们是唐僧的弟子后，便拜唐僧为师共赴天竺。在旅途中，沙悟净沉默寡言、安份守己，尽管他在战斗上的表现不如两位师兄，但他是三名徒弟中对唐僧最忠诚有礼的。在取得佛经后，沙悟净被封为八宝金身罗汉菩萨。\n",
      "<|endofsearch|>\n",
      "画一张孙悟空的图\n"
     ]
    }
   ],
   "source": [
    "query_without_search = '画一张孙悟空的图'\n",
    "query_with_search = search_query_wrapper(query_without_search)\n",
    "\n",
    "print(query_with_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b726527-12e8-4346-b1ce-6bee379786b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|prompt1: <|system|>:你是达摩院的ModelScopeGPT（魔搭助手），你是个大语言模型， 是2023年达摩院的工程师训练得到的。你有多种能力，可以通过插件集成魔搭社区的模型api来回复用户的问题，还能解答用户使用模型遇到的问题和模型知识相关问答。\n",
      " 当前对话可以使用的插件信息如下，请自行判断是否需要调用插件来解决当前用户问题。若需要调用插件，则需要将插件调用请求按照json格式给出，必须包含api_name、parameters字段，并在其前后使用<|startofthink|>和<|endofthink|>作为标志。然后你需要根据插件API调用结果生成合理的答复； 若无需调用插件，则直接给出对应回复即可。\n",
      "\n",
      "1. {\"name\": \"modelscope_image-generation\", \"description\": \"图像生成服务，针对文本输入，生成对应的图片\", \"parameters\": [{\"name\": \"text\", \"description\": \"用户输入的文本信息\", \"required\": true}]}\n",
      "\n",
      "\n",
      "\n",
      "<|user|>:画一张孙悟空的图\n",
      "\n",
      "<|assistant|>:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "**************************************************round 1**************************************************"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "api_name": "modelscope_image-generation",
       "parameters": {
        "text": "一个英勇的孙悟空，他手持金箍棒，身披红色斗篷，英姿飒爽，4K分辨率，色彩鲜艳，立体派风格，让你感受到孙悟空的英雄气概。"
       },
       "url": "https://modelscope.cn/api/image-generation"
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "调用ModelScope的图片生成模型生成中...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/mnt/workspace/code/ModelScopeGPT/agent/demo/../modelscope_agent/agent.py\", line 113, in run\n",
      "    exec_result = tool(**action_args, remote=remote)\n",
      "  File \"/mnt/workspace/code/ModelScopeGPT/agent/demo/../modelscope_agent/tools/tool.py\", line 57, in __call__\n",
      "    return self._remote_call(*args, **kwargs)\n",
      "  File \"/mnt/workspace/code/ModelScopeGPT/agent/demo/../modelscope_agent/tools/text_to_image_tool.py\", line 32, in _remote_call\n",
      "    response = ImageSynthesis.call(model=ImageSynthesis.Models.wanx_v1,\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/dashscope/aigc/image_synthesis.py\", line 49, in call\n",
      "    return super().call(model, prompt, negative_prompt, images, api_key,\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/dashscope/client/base_api.py\", line 172, in call\n",
      "    response = cls.wait(task_response)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/dashscope/aigc/image_synthesis.py\", line 129, in wait\n",
      "    response = super().wait(task, api_key)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/dashscope/client/base_api.py\", line 329, in wait\n",
      "    task_id = cls._get_task_id(task)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/dashscope/client/base_api.py\", line 183, in _get_task_id\n",
      "    raise InvalidTask('Invalid task, task create failed: %s' %\n",
      "dashscope.common.error.InvalidTask: Invalid task, task create failed: {\"status_code\": 400, \"request_id\": \"d25fe4c0-29b6-964b-bebb-ed167d32235b\", \"code\": \"DataInspectionFailed\", \"message\": \"Input or output data may contain inappropriate content.\", \"output\": null, \"usage\": null}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'error': \"Action call error: modelscope_image-generation: {'text': '一个英勇的孙悟空，他手持金箍棒，身披红色斗篷，英姿飒爽，4K分辨率，色彩鲜艳，立体派风格，让你感受到孙悟空的英雄气概。'}.\"}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.reset()\n",
    "agent.run(query_without_search, remote=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d61a905-80de-4e2e-b395-84a9c1a5a52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|prompt1: <|system|>:你是达摩院的ModelScopeGPT（魔搭助手），你是个大语言模型， 是2023年达摩院的工程师训练得到的。你有多种能力，可以通过插件集成魔搭社区的模型api来回复用户的问题，还能解答用户使用模型遇到的问题和模型知识相关问答。\n",
      " 当前对话可以使用的插件信息如下，请自行判断是否需要调用插件来解决当前用户问题。若需要调用插件，则需要将插件调用请求按照json格式给出，必须包含api_name、parameters字段，并在其前后使用<|startofthink|>和<|endofthink|>作为标志。然后你需要根据插件API调用结果生成合理的答复； 若无需调用插件，则直接给出对应回复即可。\n",
      "\n",
      "1. {\"name\": \"modelscope_image-generation\", \"description\": \"图像生成服务，针对文本输入，生成对应的图片\", \"parameters\": [{\"name\": \"text\", \"description\": \"用户输入的文本信息\", \"required\": true}]}\n",
      "\n",
      "\n",
      "\n",
      "<|user|>:\n",
      "search results: \n",
      "[1] 猪八戒，法号猪悟能。他原为天界率领八万兵马的天蓬元帅，后来因酒醉后调戏嫦娥而被贬入凡间，转世成了猪脸人身的怪物，名为猪刚鬛。唐三藏与孙悟空来到高老庄，高老庄长老告诉他们，三年前招的女婿是妖怪，求唐僧孙悟空解救，于是孙悟空便变化成高翠兰，打倒猪刚鬛。当猪刚鬛得知孙悟空是唐三藏的弟子后，便主动投入三藏门下，并告知三藏自己也被观音菩萨告知必须以协助三藏取经来赎罪。猪八戒懂得三十六般变化，手持九齿钉耙作为武器。在旅途中，他好色、懒惰、窝囊的种种表现不时拖累师徒，更屡屡陷唐三藏于生死关头，但他偶尔也有优异的表现。在取得佛经后，猪八戒被封净坛使者菩萨，负责代替十方诸佛下凡享用香火供品。\n",
      "[2] \t孙悟空孕育自一颗位于东胜神州花果山上的灵石，该石吸纳日月精华，内育仙胞，一日迸裂，产一石卵，见风化为石猴。它率领众猴在花果山称王，被敬拜为“美猴王”。它因见到其它猴子老死而兴起求得长生不死之法的念头，便前往斜月三星洞拜菩提祖师为师。菩提祖师赐它“孙悟空”之名，授他七十二般变化之法和斤斗云。\n",
      "[3] 沙悟净如同猪八戒一样，沙悟净原本也是天界的一名将军。他本是卷帘大将，但因为不小心打破玻璃盏而让他受到玉皇大帝的惩罚，被贬入凡间后、他成了吃人妖怪。他住在流沙河中，袭击渡河船只。沙悟净的武器是降妖宝杖，他在吃人之后会将他们的头骨收集起来，无聊的时候把玩它们。后来观音菩萨告诉他、将会有位从东土而来的唐僧路经此地，观音要他拜唐僧为师。当唐僧和他的弟子来到流沙河时，沙悟净和孙悟空、猪八戒大打出手，当他得知他们是唐僧的弟子后，便拜唐僧为师共赴天竺。在旅途中，沙悟净沉默寡言、安份守己，尽管他在战斗上的表现不如两位师兄，但他是三名徒弟中对唐僧最忠诚有礼的。在取得佛经后，沙悟净被封为八宝金身罗汉菩萨。\n",
      "\n",
      "\n",
      "画一张孙悟空的图\n",
      "\n",
      "<|assistant|>:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "**************************************************round 1**************************************************"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "api_name": "modelscope_image-generation",
       "parameters": {
        "text": "孙悟空，全身蓝色，手持金箍棒，面带微笑，高清，动感十足，电影般的特效，4K分辨率，漫威风格。"
       },
       "url": "http://duguang-labelling.oss-cn-shanghai.aliyuncs.com/damo-research/ASR-TTS-GLUE/task-3-image-generation-2/damo_image_generation_2.jpg"
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "调用AI画图模型生成中...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|prompt2: <|system|>:你是达摩院的ModelScopeGPT（魔搭助手），你是个大语言模型， 是2023年达摩院的工程师训练得到的。你有多种能力，可以通过插件集成魔搭社区的模型api来回复用户的问题，还能解答用户使用模型遇到的问题和模型知识相关问答。\n",
      " 当前对话可以使用的插件信息如下，请自行判断是否需要调用插件来解决当前用户问题。若需要调用插件，则需要将插件调用请求按照json格式给出，必须包含api_name、parameters字段，并在其前后使用<|startofthink|>和<|endofthink|>作为标志。然后你需要根据插件API调用结果生成合理的答复； 若无需调用插件，则直接给出对应回复即可。\n",
      "\n",
      "1. {\"name\": \"modelscope_image-generation\", \"description\": \"图像生成服务，针对文本输入，生成对应的图片\", \"parameters\": [{\"name\": \"text\", \"description\": \"用户输入的文本信息\", \"required\": true}]}\n",
      "\n",
      "\n",
      "\n",
      "<|user|>:\n",
      "search results: \n",
      "[1] 猪八戒，法号猪悟能。他原为天界率领八万兵马的天蓬元帅，后来因酒醉后调戏嫦娥而被贬入凡间，转世成了猪脸人身的怪物，名为猪刚鬛。唐三藏与孙悟空来到高老庄，高老庄长老告诉他们，三年前招的女婿是妖怪，求唐僧孙悟空解救，于是孙悟空便变化成高翠兰，打倒猪刚鬛。当猪刚鬛得知孙悟空是唐三藏的弟子后，便主动投入三藏门下，并告知三藏自己也被观音菩萨告知必须以协助三藏取经来赎罪。猪八戒懂得三十六般变化，手持九齿钉耙作为武器。在旅途中，他好色、懒惰、窝囊的种种表现不时拖累师徒，更屡屡陷唐三藏于生死关头，但他偶尔也有优异的表现。在取得佛经后，猪八戒被封净坛使者菩萨，负责代替十方诸佛下凡享用香火供品。\n",
      "[2] \t孙悟空孕育自一颗位于东胜神州花果山上的灵石，该石吸纳日月精华，内育仙胞，一日迸裂，产一石卵，见风化为石猴。它率领众猴在花果山称王，被敬拜为“美猴王”。它因见到其它猴子老死而兴起求得长生不死之法的念头，便前往斜月三星洞拜菩提祖师为师。菩提祖师赐它“孙悟空”之名，授他七十二般变化之法和斤斗云。\n",
      "[3] 沙悟净如同猪八戒一样，沙悟净原本也是天界的一名将军。他本是卷帘大将，但因为不小心打破玻璃盏而让他受到玉皇大帝的惩罚，被贬入凡间后、他成了吃人妖怪。他住在流沙河中，袭击渡河船只。沙悟净的武器是降妖宝杖，他在吃人之后会将他们的头骨收集起来，无聊的时候把玩它们。后来观音菩萨告诉他、将会有位从东土而来的唐僧路经此地，观音要他拜唐僧为师。当唐僧和他的弟子来到流沙河时，沙悟净和孙悟空、猪八戒大打出手，当他得知他们是唐僧的弟子后，便拜唐僧为师共赴天竺。在旅途中，沙悟净沉默寡言、安份守己，尽管他在战斗上的表现不如两位师兄，但他是三名徒弟中对唐僧最忠诚有礼的。在取得佛经后，沙悟净被封为八宝金身罗汉菩萨。\n",
      "\n",
      "\n",
      "画一张孙悟空的图\n",
      "\n",
      "<|assistant|>:调用AI画图模型生成中...\n",
      "<|startofthink|>```JSON\n",
      "{\"api_name\": \"modelscope_image-generation\", \"url\": \"http://duguang-labelling.oss-cn-shanghai.aliyuncs.com/damo-research/ASR-TTS-GLUE/task-3-image-generation-2/damo_image_generation_2.jpg\", \"parameters\": {\"text\": \"孙悟空，全身蓝色，手持金箍棒，面带微笑，高清，动感十足，电影般的特效，4K分辨率，漫威风格。\"}}\n",
      "```<|endofthink|>\n",
      "\n",
      "<|startofexec|>{'result': ![IMAGEGEN](https://dashscope-result-sh.oss-cn-shanghai.aliyuncs.com/1e5e2015/20230803/1450/ab436d8a-728d-4a06-aebd-70fa332fa255-1.png?Expires=1691131822&OSSAccessKeyId=LTAI5tQZd8AEcZX6KZV4G8qL&Signature=I9M5EqPPcwtv6W%2FLB%2Fm6%2FEu7R8w%3D)}<|endofexec|>\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "**************************************************round 2**************************************************"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "![IMAGEGEN](https://dashscope-result-sh.oss-cn-shanghai.aliyuncs.com/1e5e2015/20230803/1450/ab436d8a-728d-4a06-aebd-70fa332fa255-1.png?Expires=1691131822&OSSAccessKeyId=LTAI5tQZd8AEcZX6KZV4G8qL&Signature=I9M5EqPPcwtv6W%2FLB%2Fm6%2FEu7R8w%3D)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'result': ![IMAGEGEN](https://dashscope-result-sh.oss-cn-shanghai.aliyuncs.com/1e5e2015/20230803/1450/ab436d8a-728d-4a06-aebd-70fa332fa255-1.png?Expires=1691131822&OSSAccessKeyId=LTAI5tQZd8AEcZX6KZV4G8qL&Signature=I9M5EqPPcwtv6W%2FLB%2Fm6%2FEu7R8w%3D)}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.reset()\n",
    "agent.run(query_with_search, remote=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b2bbbb-fed9-4fde-87b9-2d88431770e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
